{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "imbalanced.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# instalation"
      ],
      "metadata": {
        "id": "iKUC9J_hvmaY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install hmeasure"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ayrpfagdvqA7",
        "outputId": "29e9d56b-9362-4f8d-ab19-de3e8e9b734f"
      },
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: hmeasure in /usr/local/lib/python3.7/dist-packages (0.1.6)\n",
            "Requirement already satisfied: scikit-learn>=0.21.1 in /usr/local/lib/python3.7/dist-packages (from hmeasure) (1.0.2)\n",
            "Requirement already satisfied: numpy>=1.16.1 in /usr/local/lib/python3.7/dist-packages (from hmeasure) (1.21.6)\n",
            "Requirement already satisfied: scipy>=1.2.1 in /usr/local/lib/python3.7/dist-packages (from hmeasure) (1.4.1)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.21.1->hmeasure) (1.1.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.21.1->hmeasure) (3.1.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# data\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
        "from collections import Counter\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# models\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "from sklearn.ensemble import BaggingClassifier\n",
        "from sklearn.model_selection import cross_val_score, cross_val_predict\n",
        "from sklearn.model_selection import RepeatedStratifiedKFold\n",
        "from imblearn.pipeline import Pipeline\n",
        "from imblearn.over_sampling import ADASYN, SMOTE, SVMSMOTE, BorderlineSMOTE\n",
        "from hmeasure import h_score"
      ],
      "metadata": {
        "id": "5tE9k4AGvu0o"
      },
      "execution_count": 104,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# data"
      ],
      "metadata": {
        "id": "VFixXD4e-IBe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# optional\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "eqUpBKMl8w28"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# dataset locations\n",
        "data_path = \"drive/MyDrive/datasets/creditcard.csv\"\n",
        "data_path_2 = \"drive/MyDrive/datasets/diabetes.csv\"\n",
        "data_path_3 = \"drive/MyDrive/datasets/lung_cancer.csv\""
      ],
      "metadata": {
        "id": "iX0t9CXP7GiS"
      },
      "execution_count": 93,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_dataset(path):\n",
        "    # load the dataset as a numpy array\n",
        "    dataframe = pd.read_csv(path, na_values='?')\n",
        "    # drop unnecessary columns\n",
        "    #dataframe.drop(['Time'], axis=1)\n",
        "    # change column names to numbers\n",
        "    dataframe.columns = range(dataframe.shape[1])\n",
        "    # drop rows with missing data\n",
        "    dataframe = dataframe.dropna()\n",
        "    # split into inputs and outputs\n",
        "        \n",
        "    # encode M,F in lung dataset\n",
        "    if \"cancer\" in path:\n",
        "        cleanup_nums = {0:     {\"M\": 0, \"F\": 1}}\n",
        "        dataframe = dataframe.replace(cleanup_nums)\n",
        "\n",
        "    last_id = len(dataframe.columns) - 1 # label column id\n",
        "    X, y = dataframe.drop(last_id, axis=1), dataframe[last_id]\n",
        "    # select categorical and numerical features\n",
        "    #cat_ids = X.select_dtypes(include=['object', 'bool', 'string']).columns\n",
        "    #num_ids = X.select_dtypes(include=['int64', 'float64']).columns\n",
        "\n",
        "    # label encode the target variable to have the classes 0 and 1\n",
        "    y = LabelEncoder().fit_transform(y)\n",
        "    # scale data\n",
        "    #X = StandardScaler().fit_transform(X.values)\n",
        "    return X.values, y, dataframe # cat_ids, num_ids"
      ],
      "metadata": {
        "id": "QEPERqTQ7jZi"
      },
      "execution_count": 195,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# eval\n"
      ],
      "metadata": {
        "id": "BmNFI_zMT-tO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate(X, y):\n",
        "    # define models\n",
        "    models = []\n",
        "    models.append(('CART', DecisionTreeClassifier()))\n",
        "    #models.append(('SVM', SVC(gamma='scale')))\n",
        "    #models.append(('RF', RandomForestClassifier()))\n",
        "\n",
        "    # define oversampling techniques\n",
        "    oversampling = []\n",
        "    oversampling.append(('NONE', None))\n",
        "    oversampling.append(('SMOTE', SMOTE()))             \n",
        "\n",
        "    for model in models:\n",
        "        for over in oversampling:\n",
        "\n",
        "            #define pipeline\n",
        "            steps = [('over', over[1]), ('model', model[1])]\n",
        "            pipeline = Pipeline(steps=steps)\n",
        "\n",
        "            # 5 times 2-fold cross-validation\n",
        "            cv = RepeatedStratifiedKFold(n_splits=2, n_repeats=1, random_state=1) # n_repeats=5\n",
        "\n",
        "            # roc-auc\n",
        "            #scores = cross_val_score(pipeline, X, y, scoring='roc_auc', cv=cv, verbose=2)#, n_jobs=-1)\n",
        "            #score = mean(scores)\n",
        "\n",
        "            # h-measure\n",
        "            predictions = cross_val_predict(pipeline, X, y, cv=cv, verbose=1)#, n_jobs=-1)\n",
        "            n1, n0 = y.sum(), y.shape[0]-y.sum()\n",
        "            score = h_score(y, predictions, severity_ratio=(n1/n0))\n",
        "            \n",
        "            print(f\"model: {model[0]}, type: {over[0]}, score: {score}\")"
      ],
      "metadata": {
        "id": "c9knNFTiUAdn"
      },
      "execution_count": 196,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# load chosen dataset\n",
        "X, y, df = load_dataset(data_path)\n",
        "print(X.shape, y.shape, Counter(y))\n",
        "print(X[10])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "favLasNg0NR4",
        "outputId": "ebf0838f-4777-4fdb-b443-6b56f0333d4b"
      },
      "execution_count": 198,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(284807, 30) (284807,) Counter({0: 284315, 1: 492})\n",
            "[ 1.00000000e+01  1.44904378e+00 -1.17633883e+00  9.13859833e-01\n",
            " -1.37566665e+00 -1.97138317e+00 -6.29152139e-01 -1.42323560e+00\n",
            "  4.84558879e-02 -1.72040839e+00  1.62665906e+00  1.19964395e+00\n",
            " -6.71439778e-01 -5.13947153e-01 -9.50450454e-02  2.30930409e-01\n",
            "  3.19674668e-02  2.53414716e-01  8.54343814e-01 -2.21365414e-01\n",
            " -3.87226474e-01 -9.30189652e-03  3.13894411e-01  2.77401580e-02\n",
            "  5.00512287e-01  2.51367359e-01 -1.29477954e-01  4.28498709e-02\n",
            "  1.62532619e-02  7.80000000e+00]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# optionally scale\n",
        "X = StandardScaler().fit_transform(X)"
      ],
      "metadata": {
        "id": "EGiNQ4CfFGd5"
      },
      "execution_count": 185,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "evaluate(X,y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b8UpDjdgrRsY",
        "outputId": "1f76b2b7-20dc-4449-9649-da7ddad42b22"
      },
      "execution_count": 199,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:   25.8s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "model: CART, type: NONE, score: 0.7202818177733689\n",
            "model: CART, type: SMOTE, score: 0.7351299760899928\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:   55.6s finished\n"
          ]
        }
      ]
    }
  ]
}